{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"left\">\n",
    "<img width=15% src=\"https://dai.lids.mit.edu/wp-content/uploads/2018/06/Logo_DAI_highres.png\" alt=\"SteganoGAN\" />\n",
    "<i>An open source project from Data to AI Lab at MIT.</i>\n",
    "</p>\n",
    "\n",
    "[![PyPi Shield](https://img.shields.io/pypi/v/TGAN.svg)](https://pypi.python.org/pypi/TGAN)\n",
    "[![Travis CI Shield](https://travis-ci.org/DAI-Lab/TGAN.svg?branch=master)](https://travis-ci.org/DAI-Lab/TGAN)\n",
    "\n",
    "# TGAN\n",
    "\n",
    "Generative adversarial training for synthesizing tabular data.\n",
    "\n",
    "TGAN is a tabular data synthesizer. It can generate fully synthetic data from real data. Currently, TGAN can\n",
    "generate numerical columns and categorical columns. This software can do random search for TGAN parameters\n",
    "on multiple datasets using multiple GPUs.\n",
    "\n",
    "* Free software: MIT license\n",
    "* Documentation: https://DAI-Lab.github.io/tgan\n",
    "* Homepage: https://github.com/DAI-Lab/tgan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "### Requirements\n",
    "\n",
    "#### Python\n",
    "\n",
    "**TGAN** has been developed and runs on Python [3.5](https://www.python.org/downloads/release/python-356/),\n",
    "[3.6](https://www.python.org/downloads/release/python-360/) and\n",
    "[3.7](https://www.python.org/downloads/release/python-370/).\n",
    "\n",
    "Also, although it is not strictly required, the usage of a [virtualenv](https://virtualenv.pypa.io/en/latest/)\n",
    "is highly recommended in order to avoid interfering with other software installed in the system where **TGAN**\n",
    "is run.\n",
    "\n",
    "### Installation\n",
    "\n",
    "The simplest and recommended way to install TGAN is using `pip`:\n",
    "\n",
    "```\n",
    "pip install tgan\n",
    "```\n",
    "\n",
    "Alternatively, you can also clone the repository and install it from sources\n",
    "\n",
    "```\n",
    "git clone git@github.com:DAI-Lab/tgan.git\n",
    "cd tgan\n",
    "make install\n",
    "```\n",
    "\n",
    "For development, you can use `make install-develop` instead in order to install all the required\n",
    "dependencies for testing and code linting.\n",
    "\n",
    "### Data Format\n",
    "\n",
    "#### Input\n",
    "\n",
    "In order to be able to sample new synthetic data, **TGAN** needs to first be *fitted* to existing data.\n",
    "\n",
    "The input data for this *fitting* process has to be a single table that:\n",
    "\n",
    "* Has no missing values.\n",
    "* Has columns of types `int`, `float`, `str` or `bool`.\n",
    "* Each column contains data of only one type.\n",
    "\n",
    "The following is a simple example of a table with 4 columns, `str_column`, `float_column`,`int_column`,\n",
    "`bool_column`, each one being an example of one of the supported value types.\n",
    "\n",
    "| str_column | float_column | int_column | bool_column |\n",
    "|------------|--------------|------------|-------------|\n",
    "|    'green' |         0.15 |         10 |        True |\n",
    "|     'blue' |         7.25 |         23 |       False |\n",
    "|      'red' |        10.00 |          1 |       False |\n",
    "|   'yellow' |         5.50 |         17 |        True |\n",
    "\n",
    "**NOTE**: It's important to have properly identifed which of the columns are numerical, which means\n",
    "that they represent a magnitude, and which ones are categorical, as during the preprocessing of\n",
    "the data, numerical and categorical columns will be processed differently.\n",
    "\n",
    "#### Output\n",
    "\n",
    "The output of **TGAN** is a table of sampled data with the same columns as the input table and as many rows as requested.\n",
    "\n",
    "### Demo Datasets\n",
    "\n",
    "**TGAN** includes a few datasets to use for development or demonstration purposes. These datasets\n",
    "come from the [UCI Machine Learning repository](http://archive.ics.uci.edu/ml), but have been\n",
    "preprocessed to be ready to use with **TGAN**, following the requirements specified in the `Input` section.\n",
    "\n",
    "These datasets can be browsed and directly downloaded from the\n",
    "[tgan-demo AWS S3 Bucket](https://s3.amazonaws.com/hdi-demos/tgan-demo/)\n",
    "\n",
    "#### Census dataset\n",
    "\n",
    "This dataset contains a single table, with information from the census, labeled with information of\n",
    "wheter or not the income of is greater than 50.000 $/year. It's a single csv file, containing\n",
    "199522 rows and 41 columns. From these 41 columns, only 7 are identified as continuous. In **TGAN** this\n",
    "dataset is called `census`.\n",
    "\n",
    "#### Cover type\n",
    "\n",
    "This dataset contains a single table with cartographic information labeled with the different\n",
    "forrest cover types. It's a single csv file, containing 465588 rows and 55 columns. From these\n",
    "55 columns, 10 are identified as continuous. In **TGAN** this dataset is called `covertype`.\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "In this section we will show the most basic usage of **TGAN** in order to generate samples from a\n",
    "given dataset.\n",
    "\n",
    "**NOTE**: All the examples of this tutorial are run in an [IPython Shell](https://ipython.org/),\n",
    "which you can install by running the following commands inside your *virtualenv*:\n",
    "\n",
    "```\n",
    "pip install jupyter\n",
    "jupyter notebook examples/README.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the data\n",
    "\n",
    "The first step is to load the data wich we will use to fit TGAN. In order to do so, we will first\n",
    "import the function `tgan.data.load_data` and call it with the name the dataset that we want to load.\n",
    "\n",
    "In this case, we will load the `census` dataset, which we will use during the subsequent steps, and obtain two objects:\n",
    "\n",
    "1. `data` will contain a `pandas.DataFrame` with the table of data from the `census` dataset ready to be used to fit the model.\n",
    "\n",
    "2. `continous_columns` will contain a `list` with the indices of continuous columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgan.data import load_demo_data\n",
    "\n",
    "data, continuous_columns = load_demo_data('census')\n",
    "\n",
    "data.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a TGAN instance\n",
    "\n",
    "The next step is to import TGAN and create an instance of the model.\n",
    "\n",
    "To do so, we need to import the `tgan.model.TGANModel` class and call it.\n",
    "\n",
    "This will create a TGAN instance with the default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgan.model import TGANModel\n",
    "\n",
    "tgan = TGANModel(continuous_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit the model\n",
    "\n",
    "The third step is to pass the data that we have loaded previously to the `TGANModel.fit` method to\n",
    "start the fitting.\n",
    "\n",
    "This process will not return anything, however, the progress of the fitting will be printed into screen.\n",
    "\n",
    "**NOTE** Depending on the performance of the system you are running, and the parameters selected\n",
    "for the model, this step can take up to a few hours.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgan.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Sample new data\n",
    "\n",
    "After the model has been fit, we are ready to generate new samples by calling the `TGANModel.sample`\n",
    "method passing it the desired amount of samples.\n",
    "\n",
    "The returned object, `samples`, is a `pandas.DataFrame` containing a table of synthetic data with\n",
    "the same format as the input data and 1000 rows as we requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "\n",
    "samples = tgan.sample(num_samples)\n",
    "\n",
    "samples.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save and Load a model\n",
    "\n",
    "In the steps above we saw that the fitting process is slow, so we probably would like to avoid having to fit every we want to generate samples. Instead we can fit a model once, save it, and load it every time we want to sample new data.\n",
    "\n",
    "If we have a fitted model, we can save it by calling the `TGANModel.save` method, that only takes\n",
    "as argument the path to store the model into. Similarly, the `TGANModel.load` allows to load a model stored on disk by passing as argument a path where the model is stored.\n",
    "\n",
    "At this point we could use this model instance to generate more samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'demo/my_model'\n",
    "\n",
    "tgan.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tgan = TGANModel.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_samples = new_tgan.sample(num_samples)\n",
    "\n",
    "new_samples.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading custom datasets\n",
    "\n",
    "In the previous steps we used some demonstration data but we did not show how to load your own dataset.\n",
    "\n",
    "In order to do so you can use `pandas.read_csv` by passing it the path to the CSV file that you want to load.\n",
    "\n",
    "Additionally, you will need to create 0-indexed list of columns indices to be considered continuous.\n",
    "\n",
    "For example, if we want to load a local CSV file, `path/to/my.csv`, that has as continuous columns their first 4 columns, that is, indices `[0,1,2,3]`, we would do it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/census.csv')\n",
    "\n",
    "continuous_columns = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Parameters\n",
    "\n",
    "If you want to change the default behavior of TGANModel, such as as different `batch_size` or\n",
    "`num_epochs`, you can do so by passing different arguments when creating the instance. Have b\n",
    "\n",
    "### Model general behavior\n",
    "\n",
    "* continous_columns (`list[int]`, required): List of columns to be considered continuous.\n",
    "* output (`str`, default=`output`): Path to store the model and its artifacts.\n",
    "* gpu (`list[str]`, default=`[]`): Comma separated list of GPU(s) to use.\n",
    "\n",
    "### Neural network definition and fitting\n",
    "\n",
    "* max_epoch (`int`, default=`100`): Number of epochs to use during training.\n",
    "* steps_per_epoch (`int`, default=`10000`): Number of steps to run on each epoch.\n",
    "* save_checkpoints(`bool`, default=True): Whether or not to store checkpoints of the model after each training epoch.\n",
    "* restore_session(`bool`, default=True): Whether or not continue training from the last checkpoint.\n",
    "* batch_size (`int`, default=`200`): Size of the batch to feed the model at each step.\n",
    "* z_dim (`int`, default=`100`): Number of dimensions in the noise input for the generator.\n",
    "* noise (`float`, default=`0.2`): Upper bound to the gaussian noise added to categorical columns.\n",
    "* l2norm (`float`, default=`0.00001`): L2 reguralization coefficient when computing losses.\n",
    "* learning_rate (`float`, default=`0.001`): Learning rate for the optimizer.\n",
    "* num_gen_rnn (`int`, default=`400`):\n",
    "* num_gen_feature (`int`, default=`100`): Number of features of in the generator.\n",
    "* num_dis_layers (`int`, default=`2`):\n",
    "* num_dis_hidden (`int`, default=`200`):\n",
    "* optimizer (`str`, default=`AdamOptimizer`): Name of the optimizer to use during `fit`, possible\n",
    "  values are: [`GradientDescentOptimizer`, `AdamOptimizer`, `AdadeltaOptimizer`].\n",
    "\n",
    "If we wanted to create an identical instance to the one created on step 2, but passing the arguments in a explicit way we will do something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgan = TGANModel(\n",
    "    continuous_columns,\n",
    "    output='output',\n",
    "    gpu=None,\n",
    "    max_epoch=5,\n",
    "    steps_per_epoch=10000,\n",
    "    save_checkpoints=True,\n",
    "    restore_session=True,\n",
    "    batch_size=200,\n",
    "    z_dim=200,\n",
    "    noise=0.2,\n",
    "    l2norm=0.00001,\n",
    "    learning_rate=0.001,\n",
    "    num_gen_rnn=100,\n",
    "    num_gen_feature=100,\n",
    "    num_dis_layers=1,\n",
    "    num_dis_hidden=100,\n",
    "    optimizer='AdamOptimizer'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citation\n",
    "\n",
    "If you use TGAN, please cite the following work:\n",
    "\n",
    "> Lei Xu, Kalyan Veeramachaneni. 2018. Synthesizing Tabular Data using Generative Adversarial Networks.\n",
    "\n",
    "```LaTeX\n",
    "@article{xu2018synthesizing,\n",
    "  title={Synthesizing Tabular Data using Generative Adversarial Networks},\n",
    "  author={Xu, Lei and Veeramachaneni, Kalyan},\n",
    "  journal={arXiv preprint arXiv:1811.11264},\n",
    "  year={2018}\n",
    "}\n",
    "```\n",
    "You can find the original paper [here](https://arxiv.org/pdf/1811.11264.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
